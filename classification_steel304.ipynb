{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TLT Image Classification -- Steel 304 dataset\n",
    "\n",
    "Transfer learning is the process of transferring learned features from one application to another. It is a commonly used training technique where you use a model trained on one task and re-train to use it on a different task. \n",
    "\n",
    "NVIDIA Transfer Learning Toolkit (TLT) is a simple and easy-to-use Python based AI toolkit for taking purpose-built AI models and customizing them with users' own data.\n",
    "This notebooks uses TLT to train a neural network on images of various defects in steel welding. \n",
    "It is based on the classification example of the TLT computer vision example notebook. \n",
    "https://docs.nvidia.com/tlt/tlt-user-guide/text/tlt_quick_start_guide.html#running-the-transfer-learning-toolkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up env variables for cleaner command line commands.\n",
    "import os\n",
    "\n",
    "# insert your personal key to NGC, it can be obtained for free: \n",
    "#https://docs.nvidia.com/ngc/ngc-overview/index.html#generating-api-key\n",
    "%env KEY=\n",
    "%env NUM_GPUS=1\n",
    "%env USER_EXPERIMENT_DIR=/workspace/tlt-experiments/classification\n",
    "%env DATA_DOWNLOAD_DIR=/workspace/tlt-experiments/data\n",
    "\n",
    "# Set this path if you don't run the notebook from the samples directory.\n",
    "%env NOTEBOOK_ROOT=/mnt/sdb/AI/TLT/tlt_cv_samples_v1.0.2/classification_steel304\n",
    "\n",
    "# Please define this local project directory that needs to be mapped to the TLT docker session.\n",
    "# The dataset expected to be present in $LOCAL_PROJECT_DIR/data, while the results for the steps\n",
    "# in this notebook will be stored at $LOCAL_PROJECT_DIR/classification\n",
    "\n",
    "# !PLEASE MAKE SURE TO UPDATE THIS PATH!.\n",
    "os.environ[\"LOCAL_PROJECT_DIR\"] = \"/mnt/sdb/AI/TLT/tlt_cv_samples_v1.0.2/classification_steel304\"\n",
    "\n",
    "os.environ[\"LOCAL_DATA_DIR\"] = os.path.join(\n",
    "    os.getenv(\"LOCAL_PROJECT_DIR\", os.getcwd()),\n",
    "    \"data\"\n",
    ")\n",
    "os.environ[\"LOCAL_EXPERIMENT_DIR\"] = os.path.join(\n",
    "    os.getenv(\"LOCAL_PROJECT_DIR\", os.getcwd()),\n",
    "    \"classification\"\n",
    ")\n",
    "\n",
    "# The sample spec files are present in the same path as the downloaded samples.\n",
    "os.environ[\"LOCAL_SPECS_DIR\"] = os.path.join(\n",
    "    os.getenv(\"NOTEBOOK_ROOT\", os.getcwd()),\n",
    "    \"specs\"\n",
    ")\n",
    "%env SPECS_DIR=/workspace/tlt-experiments/classification/specs\n",
    "\n",
    "# Showing list of specification files.\n",
    "!ls -rlt $LOCAL_SPECS_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping up the local directories to the TLT docker.\n",
    "import json\n",
    "import os\n",
    "mounts_file = os.path.expanduser(\"~/.tlt_mounts.json\")\n",
    "\n",
    "# Define the dictionary with the mapped drives\n",
    "drive_map = {\n",
    "    \"Mounts\": [\n",
    "        # Mapping the data directory\n",
    "        {\n",
    "            \"source\": os.environ[\"LOCAL_PROJECT_DIR\"],\n",
    "            \"destination\": \"/workspace/tlt-experiments\"\n",
    "        },\n",
    "        # Mapping the specs directory.\n",
    "        {\n",
    "            \"source\": os.environ[\"LOCAL_SPECS_DIR\"],\n",
    "            \"destination\": os.environ[\"SPECS_DIR\"]\n",
    "        },\n",
    "    ],\n",
    "    \"DockerOptions\":{\n",
    "        \"user\": \"{}:{}\".format(os.getuid(), os.getgid())\n",
    "    }\n",
    "}\n",
    "\n",
    "# Writing the mounts file.\n",
    "with open(mounts_file, \"w\") as mfile:\n",
    "    json.dump(drive_map, mfile, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat ~/.tlt_mounts.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SKIP this cell IF you have already installed the TLT launcher.\n",
    "!pip3 install nvidia-pyindex\n",
    "!pip3 install nvidia-tlt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the versions of the TLT launcher\n",
    "!tlt info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prepare datasets and pre-trained model <a class=\"anchor\" id=\"head-2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the following dataset: https://www.kaggle.com/danielbacioiu/tig-stainless-steel-304\n",
    "The dataset stems from researchers at the University of Birmingham and describes various defects that occur in steel welding. \n",
    "The dataset comes already split into a train, validation and test dataset. It is important that we use the given split as the data stems from continous camera runs. Interleving these camera runs would yield good model performance but bad performance in real world applications. \n",
    "For further infromation on the dataset take a look at their publication: http://www.sciencedirect.com/science/article/pii/S0963869518305942"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the data from kaggle into the LOCAL_DATA_DIR. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "DATA_DIR = os.environ.get('LOCAL_DATA_DIR')\n",
    "print(DATA_DIR)\n",
    "\n",
    "!ls $DATA_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Unpack the data set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify the unpacking \n",
    "!ls $LOCAL_DATA_DIR/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Split the dataset into train/val/test <a class=\"anchor\" id=\"head-1-1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install pip requirements\n",
    "!pip3 install tqdm\n",
    "!pip3 install matplotlib==3.3.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os \n",
    "from fnmatch import fnmatch\n",
    "import shutil\n",
    "import glob \n",
    "from collections import Counter\n",
    "\n",
    "DATA_DIR=os.environ.get('LOCAL_DATA_DIR')\n",
    "TARGET_DIR=os.path.join(DATA_DIR,'split')\n",
    "\n",
    "PATH_SOURCE = os.path.join(DATA_DIR,'ss304')\n",
    "\n",
    "label_list=['good_weld','burn_through','contamination','lack_of_fusion','lack_of_shielding_gas','high_travel_speed']    \n",
    "dataset_list=['valid','train','test']\n",
    "\n",
    "#make the split directory \n",
    "if not os.path.exists(TARGET_DIR):\n",
    "        os.mkdir(TARGET_DIR)\n",
    "\n",
    "for data_set in dataset_list:\n",
    "    counter1 = 0\n",
    "    with open(PATH_SOURCE + '/' + data_set + '/' + data_set + '.json') as file:\n",
    "        f_json = json.load(file)\n",
    "    \n",
    "    distribution_classes = Counter(f_json.values())\n",
    "    nClass = len(f_json)\n",
    "    \n",
    "    print(distribution_classes)\n",
    "    print(distribution_classes[0])\n",
    "    \n",
    "    #make the target directories for classes    \n",
    "    PATH_TARGET_DATASET = os.path.join(TARGET_DIR,data_set)    \n",
    "    if not os.path.exists(PATH_TARGET_DATASET):\n",
    "        os.mkdir(PATH_TARGET_DATASET)\n",
    "\n",
    "    for label in label_list:\n",
    "        label_path = os.path.join(TARGET_DIR,data_set,label)\n",
    "        if not os.path.exists(label_path):\n",
    "            os.mkdir(label_path)\n",
    "\n",
    "    suffix = '.png'\n",
    "    pattern_test = os.path.join(DATA_DIR,'ss304',data_set,'*/*')\n",
    "    print(pattern_test+suffix)\n",
    "\n",
    "    #get a image in the directory train,test,valid and look it up in the dictionary \n",
    "    #then put it in the correct new directory based on its label\n",
    "    for img in glob.glob(pattern_test+suffix):\n",
    "        image = img.replace(PATH_SOURCE+'/'+data_set+'/','')\n",
    "        \n",
    " \n",
    "        #can be used to oversample the dataset, did not improve the performance by a lot/much longer training time\n",
    "        for j in range(1):#int((nClass / distribution_classes[f_json[image]])) % distribution_classes[0] + 1):\n",
    "            copy_path=os.path.join(TARGET_DIR,data_set,label_list[f_json[image]])\n",
    "            image_mod = image.replace('/','')\n",
    "            shutil.copy(img,copy_path+'/'+ str(j) +image_mod)   \n",
    "            counter1 +=1\n",
    "    \n",
    "    print(\"Number of of images in\",data_set,\"dataset: \",counter1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls $LOCAL_DATA_DIR/split/test/good_weld"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image \n",
    "import os\n",
    "DATA_DIR=os.environ.get('LOCAL_DATA_DIR')\n",
    "\n",
    "w,h = 200,200\n",
    "fig = plt.figure(figsize=(200,200))\n",
    "\n",
    "rows = 1\n",
    "cols = 6 \n",
    "\n",
    "image = ['/split/test/burn_through/0161214-151210-run7image-0967.png',\n",
    "         '/split/test/contamination/0160705-121434-50mmLens added slugimage-0782.png',\n",
    "         '/split/test/good_weld/0160708-115129-50mmLens 200A w.s.Lev12 try joining 5mm Plateimage-0592.png',\n",
    "        '/split/test/high_travel_speed/0160705-113121-50mmLens w.s.154cm.mimage-0145.png',\n",
    "        '/split/test/lack_of_fusion/0160708-145105-50mmLens 350A w.s.Lev16 g.f.20L.m try joining 10mm Plateimage-0682.png',\n",
    "        '/split/test/lack_of_shielding_gas/0160707-111307-50mmLens 200A w.s.11.5cm.m + no shielding gasimage-0155.png']\n",
    "labels = [\"burn_trough\",\"contamination\",\"good_weld\",\"high_travel_speed\",\"lack_of_fusion\",\"lack_of_shielding\"]\n",
    "\n",
    "for i in range(1, cols*rows + 1):\n",
    "    ax = fig.add_subplot(rows, cols,i)\n",
    "    img = Image.open(str(DATA_DIR)+str(image[i-1]))\n",
    "    img = img.resize((200,200), Image.ANTIALIAS)    \n",
    "    plt.imshow(img, cmap='gray')\n",
    "    ax.set_title(labels[i-1], fontsize=150)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Download pretrained models <a class=\"anchor\" id=\"head-1-2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installing NGC CLI on the local machine.\n",
    "## Download and install\n",
    "%env CLI=ngccli_reg_linux.zip\n",
    "!mkdir -p $LOCAL_PROJECT_DIR/ngccli\n",
    "\n",
    "# Remove any previously existing CLI installations\n",
    "!rm -rf $LOCAL_PROJECT_DIR/ngccli/*\n",
    "!wget \"https://ngc.nvidia.com/downloads/$CLI\" -P $LOCAL_PROJECT_DIR/ngccli\n",
    "!unzip -u \"$LOCAL_PROJECT_DIR/ngccli/$CLI\" -d $LOCAL_PROJECT_DIR/ngccli/\n",
    "!rm $LOCAL_PROJECT_DIR/ngccli/*.zip \n",
    "os.environ[\"PATH\"]=\"{}/ngccli:{}\".format(os.getenv(\"LOCAL_PROJECT_DIR\", \"\"), os.getenv(\"PATH\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!ngc registry model list nvidia/tlt_pretrained_classification:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p $LOCAL_EXPERIMENT_DIR/pretrained_resnet18/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls $LOCAL_EXPERIMENT_DIR/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls $LOCAL_EXPERIMENT_DIR/pretrained_resnet18/tlt_pretrained_classification_vresnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull pretrained model from NGC\n",
    "!ngc registry model download-version nvidia/tlt_pretrained_classification:resnet18 --dest $LOCAL_EXPERIMENT_DIR/pretrained_resnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Check that model is downloaded into dir.\")\n",
    "!ls -l $LOCAL_EXPERIMENT_DIR/pretrained_resnet18/tlt_pretrained_classification_vresnet18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Provide training specfication <a class=\"anchor\" id=\"head-3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!cat $LOCAL_SPECS_DIR/classification_spec.cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! sudo pip3 install tensorflow "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Run TLT training <a class=\"anchor\" id=\"head-4\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo $SPECS_DIR\n",
    "!echo $USER_EXPERIMENT_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "!tlt classification train -e $SPECS_DIR/classification_spec.cfg -r $USER_EXPERIMENT_DIR/output -k $KEY --gpus 2 | tee train_RES18PRE_50EPOC_0_006Learn.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker pull nvcr.io/nvidia/tlt-streamanalytics:v3.0-dp-py3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluate trained models <a class=\"anchor\" id=\"head-5\"></a>\n",
    "\n",
    "Edit the spec file at `$SPECS_DIR/classification_spec.cfg` to point to the intended model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time    \n",
    "!tlt classification evaluate -e $SPECS_DIR/classification_spec.cfg -k $KEY  | tee eval_RES50PRE_20EPOC_0_006Learn.out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualize Inferences <a class=\"anchor\" id=\"head-9\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the checkpoint epoch number to use for the subsequent steps.\n",
    "%env EPOCH=020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tlt classification inference -e $SPECS_DIR/classification_spec.cfg \\\n",
    "                          -m $USER_EXPERIMENT_DIR/output/weights/resnet_$EPOCH.tlt \\\n",
    "                          -k $KEY -b 32 -d $DATA_DOWNLOAD_DIR/split/test/contamination \\\n",
    "                          -cm $USER_EXPERIMENT_DIR/output_retrain/classmap.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image \n",
    "import os\n",
    "import csv\n",
    "import random as rd\n",
    "\n",
    "DATA_DIR = os.environ.get('LOCAL_DATA_DIR')\n",
    "DATA_DOWNLOAD_DIR = os.environ.get('DATA_DOWNLOAD_DIR')\n",
    "csv_path = os.path.join(DATA_DIR, 'split', 'test', 'contamination', 'result.csv')\n",
    "\n",
    "with open(csv_path,newline='\\n') as csvfile:\n",
    "    results = list(csv.reader(csvfile))\n",
    "\n",
    "w,h = 200,200\n",
    "fig = plt.figure(figsize=(30,30))\n",
    "columns = 5\n",
    "rows = 1\n",
    "\n",
    "#print(results)\n",
    "for i, index in enumerate(rd.sample(range(1, len(results)), 5)):  \n",
    "    ax = fig.add_subplot(rows, columns,i+1)\n",
    "    img = Image.open(results[index][0].replace(DATA_DOWNLOAD_DIR, DATA_DIR))\n",
    "    img = img.resize((w,h), Image.ANTIALIAS)\n",
    "    plt.imshow(img,cmap='gray')\n",
    "    ax.set_title(results[index][1] + '\\n' + 'Image: ' + str(index) + ' ' +str(round(float(results[index][2]),3)), fontsize=30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
